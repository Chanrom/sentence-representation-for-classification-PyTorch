[hparam]

############ dataset #############
dataset = TREC-6
lower = True
fine_grained = False


######### word embedding #########
pretrained = glove.840B.300d


############# model ##############
# word embedding
word_vec_size = 300
fix_word_emb = False

# LSTM
encoder = LSTM
layer = 1
brnn = False
mem_size = 300
merge = mean

# softmax classifier
hid_size_cls = 300
layer_cls = 1

# parameters initialization
param_init = 0.002


############ training ############
epochs=20
batch_size = 16
lr = 0.0005
optim = rmsprop
learning_rate_decay = 0.95
weight_decay = 0
# start lr decay at this epoch
reduce_lr_at = 5
dropout = 0.5


########### evaluation ############
# how many times of evaluation in one epoch
eval_epoch = 20
# how many times of printing information in one epoch
interval = 3
