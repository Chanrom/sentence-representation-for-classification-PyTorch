[hparam]

############ dataset #############
dataset = SST
lower = False
fine_grained = False


######### word embedding #########
pretrained = glove.840B.300d


############# model ##############
# word embedding
word_vec_size = 300
fix_word_emb = False

# BCN
encoder = BCN
mtlstm_hidden_size = 600
fc_hidden_size = 300
bilstm_encoder_size = 300
bilstm_integrator_size = 300
fc_hidden_size1 = 600
mem_size = 300

# softmax classifier
hid_sizes_cls = 300,

# parameters initialization
param_init = 0.002


############ training ############
epochs=20
batch_size = 32
lr = 0.001
optim = rmsprop
learning_rate_decay = 0.95
weight_decay = 0
# start lr decay at this epoch
reduce_lr_at = 5
dropout = 0.5


########### evaluation ############
# how many times of evaluation in one epoch
eval_epoch = 20
# how many times of printing information in one epoch
interval = 3
